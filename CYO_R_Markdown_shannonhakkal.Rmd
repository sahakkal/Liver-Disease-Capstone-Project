---
title: 'Data Science Capstone: Liver Disease Prediction Project'
author: "Shannon Hakkal"
date: "4/8/2020"
output:
  pdf_document:
    number_sections: yes
    toc: yes
    toc_depth: 4
  html_document:
    df_print: paged
    toc: yes
    toc_depth: '4'
  word_document:
    toc: yes
    toc_depth: '4'
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(
    echo = TRUE,
    message = FALSE,
    warning = FALSE
)
```

# Introduction

In order to aid in doctors' diagnoses, this project was designed to evaluate various machine learning algorithms that could help predict the presence of liver disease. A large dataset was obtained from the Kaggle website and the UCI Machine Learning Repository (Lichman, 2013). This data was collected from an area northeast of Andhra Pradesh in India in 2013. 

The goal of this project was to develop multiple machine learning models and then determine which one gives the best prediction results (i.e. the highest overall accuracy). After testing five different methods, including Logistic Regression, Naive Bayes, Linear Discriminant Analysis, K-Nearest Neighbors, and Random Forest, we concluded that the Random Forest model elicited the best predictive accuracy.  

# Methods/Analysis

To complete this project, we accessed and imported the Indian Liver Patient Records dataset from the Kaggle website: https://www.kaggle.com/uciml/indian-liver-patient-records/data. We then used R to split the dataset into two subsets called “modeling” and “validation.” The modeling set was used to train and test each of the five algorithms we proposed. The validation set was only used to test the best-performing, final model at the end of the analysis.  

## Materials

The materials used for this project are listed below.

* Indian Liver Patient Records Dataset 
This can be downloaded here: https://www.kaggle.com/uciml/indian-liver-patient-records/data

* R and RStudio

## Preparations

Install packages and load libraries:
```{r packages}
if(!require(readr)) install.packages("readr", repos = "http://cran.us.r-project.org")
if(!require(tidyverse)) install.packages("tidyverse", repos = "http://cran.us.r-project.org")
if(!require(caret)) install.packages("caret", repos = "http://cran.us.r-project.org")
if(!require(data.table)) install.packages("data.table", repos = "http://cran.us.r-project.org")
if(!require(ggplot2)) install.packages("ggplot2", repos = "http://cran.us.r-project.org")
if(!require(gridExtra)) install.packages("gridExtra", repos = "http://cran.us.r-project.org")
if(!require(klaR)) install.packages("klaR", repos = "http://cran.us.r-project.org")
if(!require(rminer)) install.packages("rminer", repos = "http://cran.us.r-project.org")
if(!require(rpart)) install.packages("rpart", repos = "http://cran.us.r-project.org")
if(!require(randomForest)) install.packages("randomForest", repos = "http://cran.us.r-project.org")

library("readr") 
library("ggplot2")
library("dplyr")
library("caret")
library("tidyverse")
library("data.table")
library("gridExtra")
library("klaR")
library("rminer")
library("rpart")
library("randomForest")
```

Load dataset:
```{r data}
indian_liver_patient <-
read_csv("~/Downloads/indian_liver_patient.csv")
```
or
```{r data_dl}
dl <- tempfile()
 download.file("https://www.kaggle.com/uciml/indian-liver-patient-records/data", dl)
```

Examine the structure of the data: 
Indian Liver Patient Records is a dataset with 583 observations (rows) and 11 variables (columns). 
```{r data_structure}
str(indian_liver_patient)
```
Notice that the "Dataset" column represents the outcomes: "1" = liver disease, "2" = no liver disease.
  
## Procedure

### 1. Exploratory Data Analysis

The first step was to explore and visualize the Indian Liver Patient Records dataset.  

```{r data_head}
head(indian_liver_patient)
``` 

Compute summary statistics of the variables.
```{r summary_stats}
summary(indian_liver_patient)
```

Remove NA entries from the dataset.
```{r remove_na}
indian_liver_patient <- indian_liver_patient %>%
    filter(!is.na(Albumin_and_Globulin_Ratio))
```

Change "Gender" and "Dataset" variables to factors. 
```{r factors}
indian_liver_patient$Gender <- as.factor(indian_liver_patient$Gender) 
indian_liver_patient$Dataset <- as.factor(indian_liver_patient$Dataset)
```

Count the number of males and females in the dataset.
```{r genders}
sum(indian_liver_patient$Gender == "Male")
sum(indian_liver_patient$Gender == "Female")
```

Plot the Gender Counts.
```{r genders_plot}
ggplot(indian_liver_patient, aes(Gender)) + 
    geom_bar(aes(fill = Gender)) + 
    ggtitle("Gender Counts") + 
    theme(legend.position="none")
```

Plot the age distribution across genders. 
```{r AgeGenders_plot}
ggplot(indian_liver_patient, aes(x=Age, color=Gender)) + 
    geom_density(alpha=.5) +
    ggtitle("Age Distribution Across Genders") + 
    theme(legend.position="none")
```

Count the number of positive and negative liver disease cases in the dataset.
```{r liver_disease}
sum(indian_liver_patient$Dataset == "1")
sum(indian_liver_patient$Dataset == "2")
```

Plot the outcome distribution ("1" = liver disease or "2" = no liver disease).
```{r outcome_dist}
ggplot(indian_liver_patient, aes(Dataset)) +
    geom_bar(stat = "count", aes(fill = Dataset)) + 
    ggtitle("Distribution of Outcomes") +
    theme(legend.position = "none")
```

Plot the outcome distribution ("1" = liver disease or "2" = no liver disease) across age.
```{r AgeBoxplot}
 ggplot(indian_liver_patient, aes(x = Dataset, y = Age, group = Dataset)) +
    geom_boxplot(color = "blue", fill = "red") +
    ylab("Age") +
    ggtitle("Outcome Distribution Across Age") 
```

Plot the outcome distribution ("1" = liver disease or "2" = no liver disease) across age and genders.
```{r AgeGendersBoxplot}
indian_liver_patient %>% group_by(Dataset, Gender) %>% 
  ggplot(aes(x = Dataset, y = Age)) +
  geom_boxplot(aes(color = Gender)) +
  ylab("Age") +
  ggtitle("Outcome Distribution Across Age and Genders") 
```

The age range of the patients in the dataset is 4 to 90, with a median age of 45. There are 439 males and 140 females in the dataset. The age variable is fairly normally distributed for both genders. There is a slightly higher mean for age in the Dataset = 1 (liver disease) group than in the Dataset = 2 (no liver disease) group. Also, there is a higher mean age for males in the Dataset = 1 group than for females, but there is no significant difference between the mean ages for the genders in the Dataset = 2 group. Overall, there were 414 positive cases of liver disease and 165 negative cases of liver disease in this dataset.    

Plot the frequency distributions (histograms) of the remaining predictors.
```{r other_variables_hist}
ph1 <- ggplot(indian_liver_patient, aes(x=Total_Bilirubin)) +
    geom_histogram(binwidth=4, colour="black", alpha=.5)

ph2 <- ggplot(indian_liver_patient, aes(x=Direct_Bilirubin)) +
    geom_histogram(binwidth=1, colour="black", alpha=.5)

ph3 <- ggplot(indian_liver_patient, aes(x=Alkaline_Phosphotase)) +
    geom_histogram(binwidth=100, colour="black", alpha=.5)

ph4 <- ggplot(indian_liver_patient, aes(x=Alamine_Aminotransferase)) +
    geom_histogram(binwidth=100, colour="black", alpha=.5)

ph5 <- ggplot(indian_liver_patient, aes(x=Aspartate_Aminotransferase)) + geom_histogram(binwidth=240, colour="black", alpha=.5)

ph6 <- ggplot(indian_liver_patient, aes(x=Total_Protiens)) +
    geom_histogram(binwidth=1/3, colour="black", alpha=.5)

ph7 <- ggplot(indian_liver_patient, aes(x=Albumin)) +
    geom_histogram(binwidth=1/4, colour="black", alpha=.5)

ph8 <- ggplot(indian_liver_patient, aes(x=Albumin_and_Globulin_Ratio)) + geom_histogram(binwidth=1/7, colour="black", alpha=.5)

grid.arrange(ph1, ph2, ph3, ph4, ph5, ph6, ph7, ph8, ncol=3)
```

Plot the outcome distributions (boxplots) of the remaining predictors. 
```{r other_variables_BP}
pb1 <- ggplot(indian_liver_patient, aes(Dataset, Total_Bilirubin)) + geom_boxplot(aes(fill = Dataset), alpha = 2/3) + stat_summary(fun=mean, geom="point", shape=3, size=4) + theme(legend.position = "none")

pb2 <- ggplot(indian_liver_patient, aes(Dataset, Direct_Bilirubin)) + geom_boxplot(aes(fill = Dataset), alpha = 2/3) + stat_summary(fun=mean, geom="point", shape=3, size=4) + theme(legend.position = "none")

pb3 <- ggplot(indian_liver_patient, aes(Dataset, Alkaline_Phosphotase)) + geom_boxplot(aes(fill = Dataset), alpha = 2/3) + stat_summary(fun=mean, geom="point", shape=3, size=4) + theme(legend.position = "none")

pb4 <- ggplot(indian_liver_patient, aes(Dataset, Alamine_Aminotransferase)) + geom_boxplot(aes(fill = Dataset), alpha = 2/3) + stat_summary(fun=mean, geom="point", shape=3, size=4) + theme(legend.position = "none")

pb5 <- ggplot(indian_liver_patient, aes(Dataset, Aspartate_Aminotransferase)) + geom_boxplot(aes(fill = Dataset), alpha = 2/3) + stat_summary(fun=mean, geom="point", shape=3, size=4) + theme(legend.position = "none")

pb6 <- ggplot(indian_liver_patient, aes(Dataset, Total_Protiens)) + geom_boxplot(aes(fill = Dataset), alpha = 2/3) + stat_summary(fun=mean, geom="point", shape=3, size=4) + theme(legend.position = "none")

pb7 <- ggplot(indian_liver_patient, aes(Dataset, Albumin)) + geom_boxplot(aes(fill = Dataset), alpha = 2/3) + stat_summary(fun=mean, geom="point", shape=3, size=4) + theme(legend.position = "none")

pb8 <- ggplot(indian_liver_patient, aes(Dataset, Albumin_and_Globulin_Ratio)) + geom_boxplot(aes(fill = Dataset), alpha = 2/3) + stat_summary(fun=mean, geom="point", shape=3, size=4) + theme(legend.position = "none")

grid.arrange(pb1, pb2, pb3, pb4, pb5, pb6, pb7, pb8, ncol=3)
```

These plots illustrate that some of the variables have skewed distributions, and some of them appear to be better predictors of liver disease than others. 

### 2. Model Development

As mentioned earlier, before we began testing machine learning algorithms, we first divided the Indian Liver Patient Records dataset into two subsets: "modeling" and "validation." The modeling set would include 90% of the data, and the validation set would include the remaining 10%.

Split the dataset into "modeling" and "validation" subsets.
```{r initial_split}
dat <- as.data.frame(indian_liver_patient)
dat <-  na.omit(dat)
set.seed(1, sample.kind="Rounding")
test_index <- createDataPartition(y = dat$Dataset, times = 1, p = 0.1, list = FALSE)
modeling <- dat[-test_index,]
validation <- dat[test_index,]
```

The next step was to further split the modeling set into training and testing subsets (90%/10% again) in order to implement and evaluate the proposed algorithms. This secondary split ensured that we did not overtrain or overfit the data because the validation set remained off limits until the conclusion of the analysis. 

Divide the modeling data into train and test sets in order to explore different training models.
``` {r secondary_split}
set.seed(1, sample.kind="Rounding")
test_index2 <- createDataPartition(y = modeling$Dataset, times = 1, p = 0.1, list = FALSE)
train_set <- modeling[-test_index2,]
test_set <- modeling[test_index2,]
```

#### Logistic Regression Model

The first algorithm we tested on the modeling data was Logistic Regression (LR). We fitted the LR model to the training set, examined the most important predictors, and then used the model to make predictions on the testing set.  

```{r modelFit_LR}
modelFit_LR = train(Dataset ~ ., data = train_set, method = "glm", family = "binomial", na.action=na.omit)
modelFit_LR
```
```{r LR_imp}
LR_imp = varImp(modelFit_LR, scale = FALSE)
LR_imp
```
```{r LR_imp_plot}
plot(LR_imp)
```
```{r pred_LR}
pred_LR = predict(modelFit_LR, test_set)
confusionMatrix(pred_LR, test_set$Dataset)
```
The Logistic Regression model predicted the presence of liver disease fairly well with an accuracy of 0.7736. The two most important predictors were Total Proteins and Albumin.  

#### Random Forest Model

The second algorithm we tested on the modeling data was Random Forest (RF). We fitted the RF model to the training set, examined the most important predictors, and then used the model to make predictions on the testing set.

```{r modelFit_RF}
modelFit_RF = train(Dataset ~ ., method = "rf", data = train_set, prox = TRUE, na.action=na.omit)
modelFit_RF
```
```{r modelFit_RF_plot}
plot(modelFit_RF)
```

```{r RF_imp}
RF_imp = varImp(modelFit_RF, scale = FALSE)
RF_imp
```
```{r RF_imp_plot}
plot(RF_imp)
```
```{r pred_RF}
pred_RF = predict(modelFit_RF, test_set)
confusionMatrix(pred_RF, test_set$Dataset)
```
The Random Forest model predicted the presence of liver disease better than LR with an accuracy of 0.7925. This accuracy was optimized by using just two variables. The two most important predictors were Alkaline Phosphotase and Alamine Aminotransferase, while Aspartate Aminotransferase and Age followed close behind.		

#### Naive Bayes Model

The third algorithm we tested on the modeling data was Naive Bayes (NB). We fitted the NB model to the training set, and then used the model to make predictions on the testing set.  

```{r modelFit_nb}
modelFit_nb = train(Dataset ~., "nb", data = train_set, trControl = trainControl(method ="cv", number = 10))
modelFit_nb
```

```{r pred_nb}
pred_nb <- predict(modelFit_nb, test_set)
confusionMatrix(pred_nb, test_set$Dataset)
```
The Naive Bayes model predicted the presence of liver disease not very well with an accuracy of only 0.6981. 

#### Linear Discriminant Analysis Model

The fourth algorithm we tested on the modeling data was Linear Discriminant Analysis (LDA). We fitted the LDA model to the training set, and then used the model to make predictions on the testing set. 

```{r modelFit_lda}
modelFit_lda <- train(Dataset ~ ., data = train_set, method = "lda", na.action=na.omit)
modelFit_lda
```

```{r pred_lda}
pred_lda <- predict(modelFit_lda, test_set)
confusionMatrix(pred_lda, test_set$Dataset)
```
The Linear Discriminant Analysis model predicted the presence of liver disease better than NB, but not as well as LR or RF, with an accuracy of only 0.7358. 

#### K-Nearest Neighbors Model

The fifth algorithm we tested on the modeling data was K-Nearest Neighbors (KNN). We fitted the KNN model to the training set, and then used the model to make predictions on the testing set.

```{r modelFit_KNN}
modelFit_KNN <- train(
  Dataset ~ ., data = train_set, method = "knn",
  trControl = trainControl("cv", number = 10),
  preProcess = c("center","scale"), 
  tuneLength = 20
  )
modelFit_KNN
```
```{r modelFit_KNN_plot}
plot(modelFit_KNN)
```

```{r pred_KNN}
pred_KNN <- predict(modelFit_KNN, test_set)
confusionMatrix(pred_KNN, test_set$Dataset)
```
The K-Nearest Neighbors model predicted the presence of liver disease better than NB and LDA, but not as well as LR or RF, with a fairly good accuracy of 0.7547. 

# Results

After training and analyzing five different models of machine learning algorithms, we determined that the best and final model for prediction was the Random Forest Model. 

```{r summaryTable}
summaryTable <- data.frame("Model" = c("Naive Bayes", "Linear Discriminant Analysis", "K-Nearest Neighbors", "Logistic Regression", "Random Forest"),
 "Accuracy" = c(0.6981, 0.7358, 0.7547, 0.7736, 0.7925))
summaryTable
```

Finally, we returned to the modeling and validation sets created at the beginning of this project and tested the final Random Forest model using those original data subsets.  

```{r FinalmodelFit_RF}
FinalmodelFit_RF = train(Dataset ~ ., method = "rf", data = modeling, prox = TRUE, na.action=na.omit)
FinalmodelFit_RF
```

```{r FinalmodelFit_RF_plot}
plot(FinalmodelFit_RF)
```


```{r FinalmodelRF_imp}
FinalmodelRF_imp = varImp(FinalmodelFit_RF, scale = FALSE)
FinalmodelRF_imp
```
```{r FinalmodelRF_imp_plot}
plot(FinalmodelRF_imp)
```
```{r Finalmodelpred_RF}
Finalmodelpred_RF = predict(FinalmodelFit_RF, validation)
confusionMatrix(Finalmodelpred_RF, validation$Dataset)
```
The prediction model that we built using the Random Forest machine learning algorithm predicted the outcome of liver disease in the validation set with an accuracy of 0.7119. The most important predictors were determined to be Alkaline Phosphotase and Aspartate Aminotransferase.	The RF model also had a better balance of sensitivity and specificity than the other models.

# Conclusion

The goal of this project was to develop multiple machine learning models and then determine which one gives the best prediction results (i.e. the highest overall accuracy). We approached this task by implementing and examining the results of five different machine learning algorithms on a subset of the Indian Liver Patient Records dataset. After testing the five different methods of Logistic Regression, Naive Bayes, Linear Discriminant Analysis, K-Nearest Neighbors, and Random Forest, we concluded that the Random Forest model elicited the best predictive accuracy.

Of the five models we developed, the Random Forest Model was determined to be the best model overall. When tested on the validation set at the end of the analysis, the Random Forest Model produced an accuracy of 0.7119, which is quite effective. It also had the best balance of sensitivity and specificity of all the models tested. 

Even though we developed an efficient predictive algorithm, there are still many ways to improve upon our final model. Transforming the data  through scaling, standardization, or removing highly-correlated variables could make a big difference in the results. Furthermore, the accuracy of the predictions could be increased through the utilization of other machine learning techniques, both supervised and unsupervised, such as K-Means Clustering, Classification and Regression Trees (CART), Principle Component Analysis (PCA), or ensemble methods. Applying different types of algorithms to this data could reveal further insights to enhance the predictive efficacy. 

# References

Lichman, M. (2013). UCI Machine Learning Repository [http://archive.ics.uci.edu/ml]. Irvine, CA: University of California, School of Information and Computer Science.

